# -*- coding: utf-8 -*-
"""Bisson EDA

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yjydgm5ppYL4OZFVxSSXCol0ck5KsrCe

##Hi There
Join me on this amazing ride as I analyze the data provided to me by Bisson Exports Co to help the company better manage their resources and utilize human labour effectively.

Now, from the company, I was provided with 2 documents, one a csv (dataset) file, and the other a .json file, that shows the US cities' demogrpahies

For better understanding, Bisson Exports Co is an export company that ship products all over the United States, through their employees and they want to make better decisions and answers to their heart-burning questions.

Firstly, loading the dataset.
"""

import pandas as pd
import json


df_dirty = pd.read_csv("/content/drive/MyDrive/travel_details - travel_details.csv")
df_dirty.head()

with open("/content/drive/MyDrive/us-cities-demographics.json", "r") as f:
    demo_data = json.load(f)

    demo_df = pd.DataFrame(demo_data)
    print(demo_df.head())

df_dirty.shape

"""The above line of code shows that the BissonExports Co provided data for 418 of their employees"""

df_dirty.info()

"""From the above block of code, it shows that there are only 3 missing cells and they exist in the "Purpose of Travel" column.

Ok, from studying the csv file, I realized that there are columns such as "Travel Start Date" and "Travel End Date". These columns are not supposed to be in object form but in date-time format, so there's going to be a change in the columns
"""

df_dirty["Travel Start Date"] = pd.to_datetime(df_dirty["Travel Start Date"], errors='coerce')
df_dirty["Travel End Date"] = pd.to_datetime(df_dirty["Travel End Date"], errors='coerce')

"""Now, I want to fill up those missing columns with "Not Stated". Even though the number is small, I believe it can still have effect on the overall outcome."""

df_dirty["Purpose Of Travel"] = df_dirty["Purpose Of Travel"].fillna("Not Stated")

"""Now, checking for duplicates. Maybe an employer filled the goolge form twice (we never can tell)"""

df_dirty.duplicated().sum()

"""Great, we do not have any duplicates.

Now, we can fulfill our mission for our client, Bisson Exports Co

Now, to their heart-burning questions...

Question 1. How many employees spent above their given stipend? Extract the name of the employee, his stipend and the actual amount spent
"""

overspent = df_dirty[df_dirty["Actual Total Expenses"] > df_dirty["STIPEND"]][
    ["Employee", "STIPEND", "Actual Total Expenses"]
]

overspent_list = overspent[["Employee", "STIPEND", "Actual Total Expenses"]]

print(overspent_list.to_string(index=False))

# Employees who spent above their stipend
overspent = df_dirty[df_dirty["Actual Total Expenses"] > df_dirty["STIPEND"]]

# Unique employee names
employee_names = overspent["Employee"].unique()

# Total count
total_overspent = len(employee_names)

print("\nTotal number of employees above budget:", total_overspent)

"""Now, the administrative want to know the loaction her employees visited the most.

Let's help them find out.
"""

location_counts = df_dirty["Destination"].value_counts().reset_index()
location_counts.columns = ["Destination", "Total_Visits"]

most_visited = location_counts.iloc[0]
print("Most visited city:", most_visited["Destination"], "| Visits:", most_visited["Total_Visits"])

"""Now, the aministrators of Bisson Exports Co are interested in the affairs of one of their employees - Troy Tippett.

Again, we're here to help them stalk this employee

They want to know the city and location exactly he visited, and how much he spent.

To know the state, we have to first merge both the json file and the csv file
"""

import us  # pip install us

# Create mapping { "FL": "Florida", "CA": "California", ... }
state_map = {s.abbr: s.name for s in us.states.STATES}

!pip install us

# Split Destination into City + State
df_dirty[["City","State_abbr"]] = df_dirty["Destination"].str.split(",", expand=True)
df_dirty["City"] = df_dirty["City"].str.strip().str.title()
df_dirty["State_abbr"] = df_dirty["State_abbr"].str.strip()

# Map abbreviation to full name
df_dirty["State"] = df_dirty["State_abbr"].map(state_map)

demo_df["city"] = demo_df["city"].str.title()
demo_df["state"] = demo_df["state"].str.title()

merged = pd.merge(
    df_dirty,
    demo_df,
    left_on=["City","State"],
    right_on=["city","state"],
    how="left"
)

print(merged.head())

city, state = most_visited["Destination"].split(", ")
demo_city = demo_df[(demo_df["city"].str.upper()==city.upper()) & (demo_df["state"].str.upper()==state.upper())]
print(demo_city)

"""Now, for Troy's details"""

# Filter for Troy Tippett
troy = merged[merged["Employee"].str.contains("Troy Tippett", case=False)]

if not troy.empty:
    # Travel spend
    total_spent = troy["Actual Total Expenses"].sum()

    # City & State (assuming only one destination)
    city = troy.iloc[0]["City"]
    state = troy.iloc[0]["State"]

    # Demographics already in merged df
    avg_household = troy.iloc[0]["average_household_size"]

    # Find the most common race for that city (highest "count")
    race_data = merged[(merged["City"] == city) & (merged["State"] == state)]
    most_common_race = race_data.loc[race_data["count"].idxmax()]["race"]

    print(f"Troy Tippett spent: ${total_spent:,.2f}")
    print(f"Destination: {city}, {state}")
    print(f"Average household size: {avg_household}")
    print(f"Most common race in {city}: {most_common_race}")
else:
    print("No record found for Troy Tippett")

travel_destinations = df_dirty["Destination"].str.split(", ", expand=True)
travel_destinations.columns = ["city", "state"]
travel_destinations["city"] = travel_destinations["city"].str.upper()
travel_destinations["state"] = travel_destinations["state"].str.upper()
travel_unique_locations = set(tuple(row) for row in travel_destinations[["city", "state"]].values)

# Get unique city, state combinations from demographics data
demo_df["city"] = demo_df["city"].str.upper()
demo_df["state"] = demo_df["state"].str.upper()
demo_unique_locations = set(tuple(row) for row in demo_df[["city", "state"]].values)

# Find locations in travel data not in demographics data
missing_locations = travel_unique_locations - demo_unique_locations

print("Destinations from travel data not found in demographics data:")
for city, state in missing_locations:
    print(f"{city}, {state}")

# Employees who visited Florida
fl_visitors = merged[merged["State"].str.upper() == "FLORIDA"]
print("Employees visited Florida:", fl_visitors["Employee"].nunique())

# Gender breakdown from demographics
gender_stats = fl_visitors.groupby("City")[["male_population","female_population"]].mean()

if not gender_stats.empty:
    gender_stats.plot(kind="bar", stacked=False, figsize=(14,6),
                      title="Gender Breakdown in Florida Cities")
else:
    print("⚠️ No Florida demographics found in merged data")

# Filter Florida from demographics
fl_demo = demo_df[demo_df["state"].str.upper() == "FLORIDA"]

total_male = fl_demo["male_population"].sum()
total_female = fl_demo["female_population"].sum()

print(f"Total males in Florida: {total_male}")
print(f"Total females in Florida: {total_female}")

veterans_state = demo_df.groupby("state")["number_of_veterans"].sum().sort_values(ascending=False)
top_state = veterans_state.index[0]
print("State with most veterans:", top_state)

travellers = df_dirty[df_dirty["Destination"].str.contains(top_state)]
print("Employees who travelled there:", travellers["Employee"].unique())

"""Below, the company wants to know the gender breakdown of the most populated city.

But first, what is the most populated city?
"""

most_pop_city = demo_df.loc[demo_df["total_population"].idxmax()]
print("Most populated city:", most_pop_city["city"], most_pop_city["state"])

import matplotlib.pyplot as plt

plt.pie([most_pop_city["male_population"], most_pop_city["female_population"]],
        labels=["Male","Female"], autopct="%1.1f%%", startangle=90)
plt.title(f"Gender Breakdown: {most_pop_city['city']}")
plt.show()

"""The company seem to be so curious about certain cities in the US.

Now, they want to know the number of Veterans in the state that one of their employees - Evan Clarke, visited
"""

evan = df_dirty[df_dirty["Employee"].str.contains("Evan Clarke", case=False)]
city, state = evan.iloc[0]["Destination"].split(", ")
veterans = demo_df[(demo_df["city"].str.upper()==city.upper()) & (demo_df["state"].str.upper()==state.upper())]["number_of_veterans"].sum()
print(f"Veterans in {state}: {veterans}")

"""Now, to make better decisions, they want to know whch month has the most travels.

Why?

I think they want to know which month they might have least productivity because a higher percentage of their employees are on vacation.

Solution.
They might spread the periods where they give their employees "leave", to add productivity.
"""

import calendar

df_dirty["Month"] = df_dirty["Travel Start Date"].dt.strftime("%B")

month_order = list(calendar.month_name[1:])  # ['January', 'February', ..., 'December']

monthly_counts = df_dirty["Month"].value_counts().reindex(month_order, fill_value=0)

monthly_counts.plot(kind="bar", figsize=(12,6), title="Travels per Month")

pip freeze > requirements.txt

"""Thank you for sticking around till the end.

PS: I left the DataFrame's name as df_dirty even after cleaning.

My bad *nervous laugh emoji*

##This document was created by Miss Atinuke Towoju.
"""